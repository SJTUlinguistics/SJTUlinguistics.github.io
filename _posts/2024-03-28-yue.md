---
layout: post
title: Do Large Language Models Understand Conversational Implicature
subtitle: A case study with a Chinese sitcom
cover-img: /assets/img/path.jpg
thumbnail-img: /assets/img/thumb.png
share-img: /assets/img/path.jpg
tags: [computational linguistics]
author: 岳士森 胡海博士
---

报告人：岳士森   胡海博士
报告时间：3月28日12:30-13:30
报告地点：外院107
报告题目： Do Large Language Models Understand Conversational Implicature – A case study with a Chinese sitcom
 
讲者介绍：
岳士森，上海交通大学英语系大四本科生，研究领域为计算语言学、认知建模，在计算语言学会议EACL发表论文一篇。
胡海，上海交通大学外国语学院翻译系助理教授，毕业于印第安纳大学语言学系，主要研究领域为计算语言学。在Computational Linguistics, Digital Scholarship in the Humanities, ACL, AAAI等期刊会议发表论文十数篇。主持教育部人文社科青年项目，入选上海浦江人才计划。
 
讲座摘要：
Understanding the non-literal meaning of an utterance is critical for large language models (LLMs) to become human-like social communicators. In this work, we introduce SwordsmanImp, the first Chinese multi-turn-dialogue-based dataset aimed at conversational implicature, sourced from dialogues in the Chinese sitcom My Own Swordsman (武林外传). It includes 200 carefully handcrafted questions, all annotated with which Gricean maxims have been violated.  We test eight close-source and open-source LLMs under two tasks: a multiple-choice question

